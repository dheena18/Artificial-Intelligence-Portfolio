# Assignment 1

1. Go to Kaggle.com

2. Find a dataset that is complex enough (20+ features), diverse enough (there are both numeric and categorical features), and interesting for you.

3. Build a linear regression for one numeric variable of your choice.

4. Plot the distribution of the residuals.

5. Send the link to the google colab with your submission. 


# Assignment 2

1. Use the same dataset that you choose on Kaggle.

2. Build k-nn regression for it. Compare your results.

3. Choose a binary variable in your data. If the only reasonable variable to work with is your target, split your target into two categories and work with a new variable.

4. Build logistic regression for your categoric variable. 

5. Choose threshold that maximizes recall. Choose threshold that maximizes F-1 score. 

6. Submit your work in the same google colab you worked with already. Let it follow your first assignment. Post the link in the answer form.

# Final Project

1. Use the same dataset that you used in the previous assignments.

2. Do the test-train split.

3. Build the best regression for your target variable (based on the tools we covered in the course: linear regression, k-nn regression, decision tree, random forest). Choose the hyper parameters that minimize error on test.

4. Sample a different test set. Rerun the pipeline again with the same parameters you chose above. Print your error. Is it the same? Is it bigger? Smaller? Explain the result by leaving a comment in the notebook.

4. Submit your work in the same google colab you worked with already. Let it follow your previous assignments. Post the link in the answer form.

